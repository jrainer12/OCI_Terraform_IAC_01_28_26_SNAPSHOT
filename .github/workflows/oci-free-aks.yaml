name: Deploy-OCI-Free-OKE

on:
  workflow_dispatch:
    inputs:
      action:
        description: apply or destroy
        required: true
        default: apply
        type: choice
        options: [apply, destroy]
      skip_node_pool:
        description: Skip node pool creation - useful when at capacity
        required: false
        default: false
        type: boolean

permissions:
  contents: read
  id-token: write  # not used now; handy if you later switch to OIDC

concurrency:
  group: oci-free-oke
  cancel-in-progress: false

env:
  TF_IN_AUTOMATION: "true"
  TF_VAR_compartment_ocid: ${{ secrets.TF_VAR_COMPARTMENT_OCID }}

jobs:
  provision:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout IaC repo
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.7   # Pin to avoid AWS chunked encoding (not supported by OCI S3-compat API)
          terraform_wrapper: false   # avoid spurious exit code 1

      - name: Verify Terraform version
        run: terraform -v

      # Write OCI config + key so both Terraform (provider oci) and OCI CLI can auth
      - name: Write OCI config
        run: |
          set -euo pipefail
          mkdir -p ~/.oci
          echo "${{ secrets.OCI_PRIVATE_KEY_BASE64 }}" | base64 -d > ~/.oci/oci_api_key.pem
          chmod 600 ~/.oci/oci_api_key.pem
          cat > ~/.oci/config <<'EOF'
          [DEFAULT]
          tenancy=${{ secrets.OCI_TENANCY_OCID }}
          user=${{ secrets.OCI_USER_OCID }}
          fingerprint=${{ secrets.OCI_FINGERPRINT }}
          key_file=~/.oci/oci_api_key.pem
          region=${{ secrets.OCI_REGION }}
          EOF

      - name: Terraform init
        run: |
          set -euo pipefail
          cat > backend-config.hcl <<BACKEND_EOF
          bucket                      = "terraform-state"
          key                         = "oci-oke/terraform.tfstate"
          region                      = "${{ secrets.OCI_REGION }}"
          endpoint                    = "https://${{ secrets.OCI_OBJECT_STORAGE_NAMESPACE }}.compat.objectstorage.${{ secrets.OCI_REGION }}.oraclecloud.com"
          access_key                  = "${{ secrets.OCI_S3_ACCESS_KEY_ID }}"
          secret_key                  = "${{ secrets.OCI_S3_SECRET_ACCESS_KEY }}"
          skip_credentials_validation = true
          skip_region_validation       = true
          skip_metadata_api_check      = true
          force_path_style             = true
          BACKEND_EOF
          
          echo "✓ Backend config file created"
          echo "✓ Using S3-compatible access keys (explicitly set in config)"
          
          terraform init -no-color -input=false -backend-config=backend-config.hcl
          
          if [ -f "errored.tfstate" ]; then
            echo "Found errored.tfstate from previous run, pushing to backend..."
            terraform state push errored.tfstate || echo "Note: State push failed (may already be uploaded)"
            rm -f errored.tfstate
          fi
          
          rm -f backend-config.hcl

      - name: Terraform plan (apply path)
        if: ${{ inputs.action == 'apply' }}
        run: terraform plan -no-color -input=false -out=tfplan

      - name: Terraform apply (with retry for capacity issues)
        if: ${{ inputs.action == 'apply' }}
        run: |
          set -euo pipefail
          if [ "${{ inputs.skip_node_pool }}" == "true" ]; then
            echo "Skipping node pool creation - applying without retry logic..."
            terraform apply -no-color -input=false -auto-approve tfplan
          else
            MAX_RETRIES=3
            RETRY_DELAY=60
            
            for i in $(seq 1 $MAX_RETRIES); do
              echo "Attempt $i of $MAX_RETRIES..."
              if terraform apply -no-color -input=false -auto-approve tfplan; then
                echo "✅ Terraform apply succeeded!"
                exit 0
              else
                EXIT_CODE=$?
                if [ $i -lt $MAX_RETRIES ]; then
                  echo "⚠️  Terraform apply failed (exit code: $EXIT_CODE)"
                  echo "Checking if it's a capacity error..."
                  if terraform show 2>&1 | grep -q "Out of host capacity\|out-of-host-capacity"; then
                    echo "Detected capacity issue. Waiting ${RETRY_DELAY}s before retry..."
                    sleep $RETRY_DELAY
                    echo "Retrying..."
                  else
                    echo "Not a capacity error, failing immediately"
                    exit $EXIT_CODE
                  fi
                else
                  echo "❌ All retry attempts failed"
                  exit $EXIT_CODE
                fi
              fi
            done
          fi

      - name: Display cluster info (skip node pool mode)
        if: ${{ inputs.action == 'apply' && inputs.skip_node_pool }}
        run: |
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo "✅ Cluster created successfully (node pool skipped)"
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo "Cluster ID: $(terraform output -raw cluster_id 2>/dev/null || echo 'N/A')"
          echo ""
          echo "Node pool creation was skipped."
          echo "You can create the node pool later using:"
          echo "  - OCI Console: Cluster → Node Pools → Create"
          echo "  - Or use the create-node-pool.sh script"
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

      - name: Set TF_VAR_create_node_pool
        run: |
          if [ "${{ inputs.skip_node_pool }}" = "true" ]; then
            v=false
          else
            v=true
          fi
          echo "TF_VAR_create_node_pool=$v" >> "$GITHUB_ENV"

      - name: Terraform destroy
        if: ${{ inputs.action == 'destroy' }}
        run: terraform destroy -no-color -auto-approve

      # ----- Post-apply: fetch kubeconfig -----
      - name: Capture cluster id
        if: ${{ inputs.action == 'apply' && !inputs.skip_node_pool }}
        id: capture_cluster
        run: |
          set -euo pipefail
          terraform output -raw cluster_id > cluster_id.txt
          echo "cluster_id=$(cat cluster_id.txt)" >> "$GITHUB_OUTPUT"
          echo "✓ Cluster ID captured: $(cat cluster_id.txt)"

      - name: Install OCI CLI (container)
        if: ${{ inputs.action == 'apply' && !inputs.skip_node_pool }}
        uses: addnab/docker-run-action@v3
        with:
          image: ghcr.io/oracle/oci-cli:latest
          options: >-
            -u 0:0
            -v /home/runner/.oci:/oracle/.oci
            -e CLUSTER_OCID=${{ steps.capture_cluster.outputs.cluster_id }}
          run: |
            set -euo pipefail
            
            mkdir -p /root/.oci
            cat > /root/.oci/config <<EOF
            [DEFAULT]
            tenancy=${{ secrets.OCI_TENANCY_OCID }}
            user=${{ secrets.OCI_USER_OCID }}
            fingerprint=${{ secrets.OCI_FINGERPRINT }}
            key_file=/oracle/.oci/oci_api_key.pem
            region=${{ secrets.OCI_REGION }}
            EOF
            chmod 600 /root/.oci/config
            
            oci --version
            echo "CLUSTER_OCID=${CLUSTER_OCID}"
            mkdir -p /oracle/.kube
            oci ce cluster create-kubeconfig \
              --cluster-id "$CLUSTER_OCID" \
              --file /oracle/.kube/config \
              --region "${{ secrets.OCI_REGION }}" \
              --token-version 2.0.0
            cp -f /oracle/.kube/config kubeconfig

      - name: Upload kubeconfig artifact
        if: ${{ inputs.action == 'apply' && !inputs.skip_node_pool }}
        uses: actions/upload-artifact@v4
        with:
          name: kubeconfig
          path: kubeconfig
          if-no-files-found: error
          retention-days: 7

      - name: Setup kubectl
        if: ${{ inputs.action == 'apply' && !inputs.skip_node_pool }}
        uses: azure/setup-kubectl@v4
        with:
          version: 'latest'

      - name: Setup Helm
        if: ${{ inputs.action == 'apply' && !inputs.skip_node_pool }}
        uses: azure/setup-helm@v4
        with:
          version: 'latest'

      - name: Use kubeconfig and verify cluster access
        if: ${{ inputs.action == 'apply' && !inputs.skip_node_pool }}
        run: |
          set -euo pipefail
          mkdir -p $HOME/.kube
          mv kubeconfig $HOME/.kube/config
          chmod 600 $HOME/.kube/config
          
          echo "Waiting for nodes to be ready..."
          kubectl wait --for=condition=Ready nodes --all --timeout=10m || true
          kubectl get nodes
          
          echo "Verifying cluster access..."
          kubectl get po -n kube-system

      - name: Wait for node pool to be ready
        if: ${{ inputs.action == 'apply' && !inputs.skip_node_pool }}
        run: |
          set -euo pipefail
          echo "Waiting for all nodes in node pool to be ready..."
          for i in {1..90}; do
            READY_NODES=$(kubectl get nodes --no-headers 2>/dev/null | grep -c " Ready " || echo "0")
            TOTAL_NODES=$(kubectl get nodes --no-headers 2>/dev/null | wc -l || echo "0")
            if [ "$READY_NODES" -ge 4 ] && [ "$TOTAL_NODES" -ge 4 ]; then
              echo "✓ All 4 nodes are ready!"
              kubectl get nodes
              break
            fi
            echo "Waiting for nodes... ($READY_NODES/$TOTAL_NODES ready, attempt $i/90)"
            sleep 10
          done